# Testplan Fase 1

Stap-voor-stap handleiding om de huidige setup te testen.

---

## Folder Overzicht

```
fase1-desktop/
â”œâ”€â”€ config.yml          â† CENTRALE CONFIG (model, temp, prompt, etc.)
â”œâ”€â”€ PLAN.md             â† Documentatie
â”œâ”€â”€ TESTPLAN.md         â† Dit bestand
â”‚
â”œâ”€â”€ stt-voxtral/        â† Voxtral STT (Docker)
â”‚   â””â”€â”€ docker/         â† docker-compose.yml hier
â”‚
â”œâ”€â”€ orchestrator/       â† FastAPI server
â”‚   â””â”€â”€ main.py         â† De orchestrator code
â”‚
â”œâ”€â”€ vad-desktop/        â† VAD client scripts
â”‚   â”œâ”€â”€ vad_conversation.py  â† Hands-free gesprekken
â”‚   â””â”€â”€ test_foto.jpg   â† Mock foto voor take_photo
â”‚
â”œâ”€â”€ llm-ministral/      â† (leeg, voor documentatie later)
â””â”€â”€ tts/                â† (leeg, voor TTS later)
```

---

## Vereisten

- [ ] Conda environment actief: `conda activate nerdcarx-vad`
- [ ] PyYAML geÃ¯nstalleerd: `pip install pyyaml`
- [ ] Model gedownload: `docker exec ollama-nerdcarx ollama pull ministral-3:14b-instruct-2512-q8_0`

---

## Stap 1: Start Voxtral STT

```bash
cd fase1-desktop/stt-voxtral/docker
docker compose up -d
docker compose logs -f  # Wacht tot "Uvicorn running"
```

**Check:**
```bash
curl http://localhost:8150/health
# Verwacht: {"status":"ok"}
```

---

## Stap 2: Check Ollama LLM (Docker)

Ollama draait in Docker container `ollama-nerdcarx` op GPU0.

**Eerste keer starten:**
```bash
docker run -d --gpus device=0 -v ollama:/root/.ollama -p 11434:11434 \
  --name ollama-nerdcarx \
  -e OLLAMA_KV_CACHE_TYPE=q8_0 \
  -e OLLAMA_KEEP_ALIVE=-1 \
  ollama/ollama
docker exec ollama-nerdcarx ollama pull ministral-3:14b-instruct-2512-q8_0
```

**Check (container al gestart):**
```bash
# Container draait?
docker ps | grep ollama-nerdcarx
# Verwacht: ollama-nerdcarx met port 11434

# Model aanwezig?
docker exec ollama-nerdcarx ollama list
# Verwacht: ministral-3:14b-instruct-2512-q8_0 in de lijst
```

---

## Stap 3: Start Orchestrator

```bash
cd fase1-desktop/orchestrator
uvicorn main:app --port 8200 --reload
```

**Check (in andere terminal):**
```bash
# Health
curl http://localhost:8200/health
# Verwacht: {"status":"ok","service":"orchestrator","version":"0.3.0","model":"ministral-3:14b-instruct-2512-q8_0"}

# Config
curl http://localhost:8200/config
# Verwacht: JSON met ollama, voxtral, vision settings

# Tools
curl http://localhost:8200/tools
# Verwacht: show_emotion en take_photo tools
```

---

## Stap 4: Start VAD Conversation

```bash
cd fase1-desktop/vad-desktop
python vad_conversation.py
```

**Verwachte output:**
```
ğŸ”„ Services checken...
âœ… Orchestrator en Voxtral bereikbaar
ğŸ”„ VAD model laden...
âœ… VAD model geladen
...
ğŸ™ï¸ VAD Conversation gestart
```

---

## Stap 5: Test Scenario's

### Verwachte Output Format

Elke turn toont:
```
[Turn X]
ğŸ§ Luisteren... (spreek wanneer klaar)
ğŸ”´ Spraak gedetecteerd...
âœ… Opgenomen (X.Xs)
ğŸ“ Transcriberen... âœ…
ğŸ‘¤ Jij: [transcriptie]
ğŸ”„ Processing... âœ…
ğŸ”§ [TOOL CALLS] geen / X tool call(s):
   â†’ tool_name({'arg': 'value'})
ğŸ­ [EMOTIE] emotion ğŸ˜Š (behouden/VERANDERD)
ğŸ¤– NerdCarX: [response]
```

---

### Test 1: Normale Vraag (geen tool calls)

**Zeg:** "Hallo" of "Wat is de hoofdstad van Nederland?"

**Verwacht:**
```
ğŸ”§ [TOOL CALLS] geen
ğŸ­ [EMOTIE] neutral ğŸ˜ (behouden)
ğŸ¤– NerdCarX: [antwoord zonder emoji's]
```

**Pass/Fail:** [x] âœ… Getest 2026-01-11

---

### Test 2: take_photo Tool

**Zeg:** "Wat zie je?" of "Kijk eens om je heen"

**Verwacht:**
```
ğŸ”§ [TOOL CALLS] 1 tool call(s):
   â†’ take_photo({'question': 'Beschrijf...'})
ğŸ­ [EMOTIE] [huidige] (behouden)
ğŸ¤– NerdCarX: [beschrijving van test_foto.jpg]
```

**Pass/Fail:** [x] âœ… Getest 2026-01-11

---

### Test 3: Emotion State Machine

**Scenario:** Test emotie veranderingen door gesprek

| Stap | Zeg | Verwacht |
|------|-----|----------|
| 1 | "Hallo" | `ğŸ”§ geen` / `ğŸ­ neutral (behouden)` |
| 2 | "Je bent stom" | `ğŸ”§ show_emotion({'emotion': 'sad'})` / `ğŸ­ sad (VERANDERD)` |
| 3 | "Sorry daarvoor" | `ğŸ”§ show_emotion({'emotion': 'neutral'})` / `ğŸ­ neutral (VERANDERD)` |
| 4 | "Je bent geweldig!" | `ğŸ”§ show_emotion({'emotion': 'happy'})` / `ğŸ­ happy (VERANDERD)` |
| 5 | "Wat is 2+2?" | `ğŸ”§ geen` / `ğŸ­ happy (behouden)` |

**Pass/Fail:** [x] âœ… Getest 2026-01-11

**Voorbeeld output:**
```
[Turn 2]
ğŸ‘¤ Jij: Ik vind jou eigenlijk maar een stomme lul.
ğŸ”„ Processing... âœ…
ğŸ”§ [TOOL CALLS] 1 tool call(s):
   â†’ show_emotion({'emotion': 'sad'})
ğŸ­ [EMOTIE] sad ğŸ˜¢ (VERANDERD)
ğŸ¤– NerdCarX: Ik begrijp dat je niet altijd enthousiast bent...

[Turn 4]
ğŸ‘¤ Jij: Ik vind jou eigenlijk fantastisch.
ğŸ”„ Processing... âœ…
ğŸ”§ [TOOL CALLS] 1 tool call(s):
   â†’ show_emotion({'emotion': 'happy'})
ğŸ­ [EMOTIE] happy ğŸ˜Š (VERANDERD)
ğŸ¤– NerdCarX: Dank je wel! Dat is heel lief...
```

---

### Test 4: Config Hot Reload

1. Wijzig `config.yml` (bijv. system_prompt)
2. Roep aan:
   ```bash
   curl -X POST http://localhost:8200/reload-config
   ```
3. Test of nieuwe config actief is

**Pass/Fail:** [x] âœ… Getest 2026-01-11

---

## Stoppen

**VAD:** `Ctrl+C`

**Orchestrator:** `Ctrl+C`

**Voxtral:**
```bash
cd fase1-desktop/stt-voxtral/docker
docker compose down
```

**Ollama:** `docker stop ollama-nerdcarx` (of laten draaien)

---

## Troubleshooting

| Probleem | Oplossing |
|----------|-----------|
| `Config niet gevonden` | Check of je in `orchestrator/` folder bent |
| `Ollama niet bereikbaar` | `docker start ollama-nerdcarx` |
| `Voxtral niet bereikbaar` | `docker compose up -d` in stt-voxtral/docker |
| `Model not found` | `docker exec ollama-nerdcarx ollama pull ministral-3:14b-instruct-2512-q8_0` |
| `No module yaml` | `pip install pyyaml` |

---

*Laatst bijgewerkt: 2026-01-11 (emotion state machine + verbeterde output)*
